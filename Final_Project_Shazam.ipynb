{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKlvHny-U9sb"
   },
   "source": [
    "# EE 341–Audio Fingerprint / Shazam - Lab 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "id": "gvq9NlRwU9sf"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import fftpack\n",
    "import scipy.io.wavfile as wav\n",
    "from scipy.ndimage.filters import maximum_filter\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.ndimage.morphology import generate_binary_structure, binary_erosion, iterate_structure\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import argrelextrema\n",
    "import simpleaudio as sa\n",
    "import os\n",
    "import math\n",
    "from scipy.stats import mode\n",
    "\n",
    "import scipy.io.wavfile as wav\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "from scipy.signal import butter, lfilter, freqz, tf2zpk\n",
    "import simpleaudio as sa\n",
    "from IPython.display import Audio\n",
    "from pydub import AudioSegment # allows conversion from mp3 to wav\n",
    "import hashlib\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sehDRtDUU9sg"
   },
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BrcxYJ4lU9sh"
   },
   "source": [
    "In this project, you will build a simple Shazam-like system to identify a short clip of a song from a database of songs. Shazam (supposedly) has a database of songs matching their unique features(fingerprints). When the system is fed with a song with its name to be detected, the system does the following\n",
    "- Obtains the song’s fingerprint \n",
    "- Matches the fingerprint with the ones that are stored in the database\n",
    "- Returns a song whose fingerprint has the closest match to the ones from the song to be detected.\n",
    "\n",
    "The feature of a song is obtained by marking its local peaks location in the magnitude of its spectrogram. A spectrogram is a plot of Time-Dependent Fourier Transform of a song."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqiR5nvUU9si"
   },
   "source": [
    "Spectrogram and Time-Dependent Fourier Transform\n",
    "\n",
    "A spectrogram is an extension of a spectrum. Recall that a spectrum could be generated by Fourier Transform for a whole signal. It is a 2D graph (Magnitude / Phase vs Frequency) which shows the frequency components of the signal. Whereas the spectrogram is a 3D plot that adds a time dimension on the top of the two dimensions from Fourier Transform (Magnitude / Phase and Frequency). A spectrogram of a signal could be obtained by Time-Dependent Fourier Transform (which is also called Short-time Fourier Transform). It could be interpreted as a Fourier Transform that depends on time. Here the Fourier Transform no longer applies to the whole signal, instead, it applies to a fixed short-time segment of the signal. Thus, as we choose different segments of the signal, we will obtain different Fourier Transforms of the segments. In this way, we could plot the spectrogram of the whole signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9sqmbFfU9si"
   },
   "source": [
    "So far we have learned that the database of the Shazam-like system stores a table of song names with the features corresponding to the song. For each song, we mark the frequencies and time of the peaks as features. To simplify calculation, we will only use paris of peaks that are close in both time and frequency as features. Thus, the database would keep a table with one row for each peak pair with the song id they belong to like follows\n",
    "\n",
    "| t1| t2 | f1 | f2|songid |\n",
    "|---|--- |----|---|-------|\n",
    "|324|328 |  26|34 |\"song1\"|\n",
    "|...|... |...|...|...|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50HQ9aoZU9sj"
   },
   "source": [
    "For each song in the Shazam database, these feature pairs arestored in a hash table for easy access. The hash value is calculated from the vector $(f_1, f_2, t_2- t_1)$ so that the same frequencies and separation in time are considered a match. In this way, it will be robust to possible time distortion. \n",
    "\n",
    "We could then store the timing $t_1$ and $songid$ in the hash table. When a clip of song is to be identified, the list of pairs of peaks is produced, just as it would havebeen for a song in the database. Then the hash table is searched for each pair in the clip. This will produce a list of matches, each with different stored values of $t_1$ and songid. Some of these matches will be accidental, either because the same peak pair occurred at another time or in another song, or because the hash table had a collision. However, we expect the correct song match to have a consistent timing offset from the clip. That is, the difference between $t_1$ for the song and $t_1$ for the clip should be the same for all correct matches. The song with the most matches for a single timing offset is declared the winner.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLAHFJolU9sk"
   },
   "source": [
    "We will use `SciPy` package for the whole lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZpC9CpkU9sk"
   },
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rl2bPnFXU9sl"
   },
   "source": [
    "Part 1 of the project will be buiding the database for the songs. You would use any MP3 files you want. (We suggest the MP3 with vocal since Shazam performs worse for the ones without vocal) The main steps are the following:\n",
    "- Read in the song using `wavfile.read`.\n",
    "- Average the two channels, subtract the mean, and downsample.\n",
    "- Compute the spectrogram of the song using `spectrogram`.\n",
    "- Find the local peaks of the spectrogram by using `circshift` in a loop.\n",
    "- Threshold the result of step 5 to end up with a specified rate of peaks retained per second of sound.\n",
    "- Find pairs of proximal peaks and add load them into a hash table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93wj-mSNU9sl"
   },
   "source": [
    "### 1.1 Reading an MP3 File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "id": "xCtQ-OWgU9sm"
   },
   "outputs": [],
   "source": [
    "# param trained: determine the file is for training database or importing to find a match\n",
    "def wav_load(file_name, trained = True): \n",
    "    \"\"\"\n",
    "    Takes in a mp3 file and returns the signal data and sampling rate\n",
    "    \"\"\"\n",
    "    header = file_name.rpartition('.')[0]\n",
    "    dst = '/Users/shuku/Desktop/EE 341/Lab6/wavSongList/'+header+'.wav'\n",
    "    # convert wav to mp3\n",
    "    if(trained):\n",
    "        sound = AudioSegment.from_mp3('/Users/shuku/Desktop/EE 341/Lab6/songlist/'+file_name)\n",
    "    else:\n",
    "        sound = AudioSegment.from_mp3(file_name)\n",
    "        \n",
    "    sound.export(dst, format=\"wav\")\n",
    "    sr, data = wav.read(dst) \n",
    "    \n",
    "    return sr, data \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFVRXOUqU9sn"
   },
   "source": [
    "### 1.2 Preprocessing\n",
    "\n",
    "Here you should average the two channels of the audio file, subtract the mean of the signal, and downsample it to 8000 Hz using `signal.resample`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "id": "mst0OlWbU9so"
   },
   "outputs": [],
   "source": [
    "def preprocess(data, sr) :\n",
    "    \"\"\"\n",
    "    Takes in signal data and sampling rate, averages the two channels when necessary, subtracts\n",
    "    the mean of the signal, and downsamples it to 8000 Hz\n",
    "    \"\"\"\n",
    "    sec = len(data) / sr\n",
    "    num = int(sec * 8000) # number of samples\n",
    "\n",
    "    channel1 = data[:, 0]\n",
    "    channel2 = data[:, 1]\n",
    "\n",
    "    avg = (channel1 + channel2) / 2\n",
    "    mean = np.mean(data)\n",
    "\n",
    "    substraction = avg - mean\n",
    "\n",
    "    resampled = signal.resample(substraction, num)\n",
    "\n",
    "    return resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBfI3_9WU9sp"
   },
   "source": [
    "### 1.3 Creating Spectrogram\n",
    "\n",
    "Here you should construct the spectrogram of the signal using `signal.spectrogram`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "id": "OH0vgIQnU9sp"
   },
   "outputs": [],
   "source": [
    "def specgram(dat, sr = 8000) :\n",
    "    \"\"\"\n",
    "    Takes in signal data and its sampling rate and produces a spectrogram for the signal\n",
    "    f=Array of sample frequencies.\n",
    "    t=Array of segment times.\n",
    "    sxx=Spectrogram of x. By default, the last axis of Sxx corresponds to the segment times.\n",
    "    \"\"\"\n",
    "    \n",
    "    f, t, sxx = signal.spectrogram(dat, sr)\n",
    "    \n",
    "    plt.pcolormesh(t, f, sxx)\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.show()\n",
    "    return f, t, sxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OzUWQ8zfU9sz"
   },
   "source": [
    "### 1.4 Finding Local Peaks\n",
    "\n",
    "Next, we find the local peaks of the spectrogram and produce a binary matrix (the same size as the spec- trogram) with a 1 at each location of a peak.\n",
    "\n",
    "Create a function `peak_counts` that does the following:\n",
    "- `peak_counts`: takes as input `peak_matrix` and checks if entries in this matrix (which has binary values) have a 1. If so increase a counter and then return the count of the number of peaks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "id": "PjznhT7HU9s1"
   },
   "outputs": [],
   "source": [
    "def peak_counts(peak_matrix) :\n",
    "    \"\"\"\n",
    "    Takes in a binary matrix denoting the peaks of a spectrogram\n",
    "    and eturns the total bumber of peaks in the matrix\n",
    "    \"\"\"\n",
    "    peak_counts = 0\n",
    "    for i in range(len(peak_matrix)) :\n",
    "        for j in range(len(peak_matrix[0])) :\n",
    "            if (peak_matrix[i,j] == 1) :\n",
    "                peak_counts = peak_counts + 1\n",
    "    return peak_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCyvTKSgU9s3"
   },
   "source": [
    "### 1.5 Thresholding\n",
    "\n",
    "We want to only use the larger peaks.Set up a poper threshold and get rid of the small peaks.\n",
    "\n",
    "For example,  if $A$ is your matrix consider checking when the differences of two consecutive row elements of the matrix are larger than 2xmean. For instance,\n",
    "$$A[i,j] - A[i - 1,j] - 0.2 \\mu > 0$$ and\n",
    " $$A[i,j] - A[i + 1,j] - 0.2  \\mu > 0$$\n",
    " where $\\mu$ is the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "id": "zeBCJ5KKU9s4"
   },
   "outputs": [],
   "source": [
    "def find_peaks(f, t, sxx) : \n",
    "    \"\"\"\n",
    "    Takes in spectrogram data sxx and returns a binary matrix\n",
    "    denoting significant peaks in the data whose magnitude\n",
    "    surpasses a variable threshold\n",
    "    \"\"\"\n",
    "    peak_matrix = np.zeros((len(f), len(t)))\n",
    "    mean = np.mean(sxx)\n",
    "    for i in range(len(f) - 1) :\n",
    "        for j in range(len(t)) :\n",
    "            if (sxx[i][j] - sxx[i - 1][j] - 0.8 * mean > 0) & (sxx[i][j] - sxx[i + 1][j] - 0.8 * mean > 0) :\n",
    "                peak_matrix[i][j] = 1\n",
    "    print('number of peaks: ', peak_counts(peak_matrix))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.pcolormesh(t, f, sxx)\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.show()\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.imshow(peak_matrix);\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "    return peak_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kn-I5Yg2NKcU"
   },
   "source": [
    "## Part 1.6 and 1.7\n",
    "\n",
    "\n",
    "### 1.6 Finding peak pairs\n",
    "\n",
    "Define a function `ctp` that does the following. The code finds pairs by considering each peak and looking for other peaks within a designated window located relative to it. During the search, we limit the number of pairs that we accept by the parameter fanout. The code is written to scan through the window column by column, accepting the first pairings that it finds. \n",
    "\n",
    "### 1.7 \n",
    "- `simple_hash`:  Simple hash function which hashes input frequency data. Given the frequencies and the time difference of the peak pair (f_1, f_2, t_2 − t_1) compute the hash value. For example: hashvalue = $mod(round(size\\*1000000\\*(log(abs(f1)+2) + 2\\*log(abs(f2)+2) + 3\\*log(abs(deltaT)+2)) ), size) + 1. You will use this in the next function\n",
    "- `add_to_table`: Adds peak-pair information from song's fingerprint to the hashtabl. In this function, you first compute the hashvalue using 'simple_hash', after that check if the hashvalue if used. If it is not used add the songid and frequencies and corresponding time to the hastable, otherwise append the songid and frequencies and so on.\n",
    "- `fingerprint`: Create a function that takes in an array of data and its sample rate, and returns a peak matrix of the data\n",
    "    It should combine functions from section one into one place and removes graphing commands\n",
    "- `make_database`: searches for all MP3 files in a designated folder and processes them if they are not already in the database\n",
    "\n",
    "    Create a function that changes global variables: `hashtable`, `songid` by\n",
    "    checking to see if the database (hashtable and songid files) already has been created in local directory. \n",
    "    If so, then these are imported. If not, then they are created.\n",
    "    Then it checks if all files in the \"songs\" folder of local directory have been added to the database.\n",
    "    If not then it adds them.\n",
    "    Saves database (hashtable and songid files) in local director\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctp(peaks):\n",
    "    \"\"\"\n",
    "    Finds pairs of peaks that are close in time and frequency from\n",
    "    a binary matrix that denotes the location of peaks in discrete time\n",
    "    and frequency.\n",
    "    Returns an array of tuples containing peak pair data\n",
    "    \"\"\"\n",
    "    \n",
    "    del_t = 35\n",
    "    del_f = 30\n",
    "    fanout = 3 # maiximum distance between peaks\n",
    "    \n",
    "    f, t = np.nonzero(peaks)\n",
    "    tup = np.zeros((fanout*len(f), 4))\n",
    "    \n",
    "    index = 0\n",
    "    \n",
    "    for i in range(len(f)):\n",
    "        links = 0\n",
    "        for f2 in range(min(peaks.shape[0], f[i] + 1), min(peaks.shape[0], f[i] + del_f)):\n",
    "            if (peaks[f2, t[i]]):\n",
    "                tup[index,:] = [t[i], t[i], f[i], f2]\n",
    "                links = links + 1\n",
    "                index = index + 1\n",
    "            if links >= fanout:\n",
    "                break\n",
    "                    \n",
    "        for t2 in range(min(peaks.shape[0], t[i] + 1), min(peaks.shape[1], t[i] + del_t)):\n",
    "            if (links >= fanout):\n",
    "                break\n",
    "            for f2 in range(max(1, f[i] - del_f), min(peaks.shape[0], f[i] + del_f)):\n",
    "                if (links >= fanout):\n",
    "                    break\n",
    "                if (peaks[f2, t2]):\n",
    "                    tup[index,:] = [t[i], t2, f[i], f2]\n",
    "                    links = links + 1\n",
    "                    index = index + 1\n",
    "    tup = tup[0:index,:]\n",
    "    \n",
    "    return tup # return the peak pair data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fingerprint(sr, data):\n",
    "    \"\"\"\n",
    "    Takes in an array of data and its sample rate. Returns a peak matrix of the data\n",
    "    Combines functions from section one into one place and removes graphing commands\n",
    "    \"\"\"\n",
    "    #TODO preprocess the data and return the peak matrix\n",
    "    data = preprocess(data, sr)\n",
    "    fs = 8000.0\n",
    "\n",
    "    f, t, sxx = signal.spectrogram(data, fs)\n",
    "    \n",
    "    peak_matrix = np.zeros((len(f), len(t)))\n",
    "    mean = np.mean(sxx)\n",
    "    for i in range(len(f) - 1) :\n",
    "        for j in range(len(t)) :\n",
    "            if (sxx[i][j] - sxx[i - 1][j] - 0.8 * mean > 0) & (sxx[i][j] - sxx[i + 1][j] - 0.8 * mean > 0) :\n",
    "                peak_matrix[i][j] = 1\n",
    "            \n",
    "    return peak_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "id": "SLiOk5saNQqy"
   },
   "outputs": [],
   "source": [
    "def simple_hash(f1, f2, deltaT, size):\n",
    "    \"\"\"\n",
    "    Simple hash function which hashes input frequency data\n",
    "    f1: the \n",
    "    \"\"\"\n",
    "    return np.mod(round(size*1000000*(np.log(abs(f1)+2) + 2*np.log(abs(f2)+2) + 3*np.log(abs(deltaT)+2)) ), size) + 1\n",
    "\n",
    "def add_to_table(tup, songid):\n",
    "    \"\"\"\n",
    "    This function changes global variable: hashtable\n",
    "    Adds peak-pair information from song's fingerprint to the hashtable\n",
    "    \"\"\"\n",
    "    global hashtable\n",
    "\n",
    "    hash_song_dict = hashtable[0]\n",
    "    hash_pair_dict = hashtable[1]\n",
    "\n",
    "\n",
    "\n",
    "    for m in range(len(tup)):\n",
    "        # s_hash is the key of the two dict\n",
    "        s_hash = simple_hash(tup[m][2], tup[m][3], tup[m][1]-tup[m][0], 100000)\n",
    "        \n",
    "        value = [tup[m][0], tup[m][1], tup[m][2], tup[m][3], songid]\n",
    "        \n",
    "\n",
    "        if (s_hash not in hash_song_dict.keys()): \n",
    "            # TODO\n",
    "            hash_song_dict[s_hash] = []\n",
    "            hash_pair_dict[s_hash] = []\n",
    "        # append value to the corresponding keys\n",
    "        hash_song_dict[s_hash].append(songid) \n",
    "        hash_pair_dict[s_hash].append(value)\n",
    "        \n",
    "    \n",
    "def make_database():\n",
    "    \"\"\"\n",
    "    This functino changes global variables: hashtable, songid\n",
    "    Checks to see if database (hashtable and songid files) have already been created in local directory\n",
    "    If so, then these are imported. If not, then they are created.\n",
    "    Checks if all files in the \"songs\" folder of local directory have been added to the database.\n",
    "    If not then it adds them.\n",
    "    Saves database (hashtable and songid files) in local directory\n",
    "    \"\"\"\n",
    "    global hashtable\n",
    "    global songid \n",
    "    \n",
    "    #TODO\n",
    "    \n",
    "    #Checks if local copy of database exists and imports\n",
    "    if (os.path.exists('hashtable.npy') and os.path.exists('songid.npy')):\n",
    "        #TODO\n",
    "        print('exists!')\n",
    "        hashtable = np.load('hashtable.npy', allow_pickle=True)\n",
    "        songid = np.load('songid.npy', allow_pickle=True)\n",
    "    else: #Creates one if not\n",
    "        #TODO\n",
    "        # store as dictionary\n",
    "        print('not exists!')\n",
    "        hash_song_dict = {} # songid\n",
    "        hash_pair_dict = {} # feature\n",
    "        \n",
    "#       hashtable: list of 2 dict\n",
    "        hashtable = [hash_song_dict, hash_pair_dict]\n",
    "\n",
    "        np.save('hashtable.npy', hashtable)\n",
    "        \n",
    "        songid = np.empty(10).astype(str)\n",
    "        np.save('songid.npy', songid)\n",
    "\n",
    "    path = '/Users/shuku/Desktop/EE 341/Lab6/songlist'\n",
    "    songlist = os.listdir(path)\n",
    "    # this part not sure\n",
    "    for i in range(len(songlist)):\n",
    "        song_name = songlist[i]\n",
    "        if(song_name[-4:] == '.mp3'): # make sure song in music file\n",
    "            if (song_name not in songid):\n",
    "                print(song_name)\n",
    "                songid[i] = song_name # add to songid.npy\n",
    "                sr, data = wav_load(song_name)\n",
    "                peak_matrix = fingerprint(sr, data)\n",
    "                tup = ctp(peak_matrix)\n",
    "                add_to_table(tup, song_name) # add to table\n",
    "    np.save('hashtable.npy', hashtable)\n",
    "    np.save('songid.npy', songid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "id": "K_pIFPGNPnNM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exists!\n",
      "Canon.mp3\n",
      "Men Without Hats.mp3\n",
      "Blinding Lights.mp3\n",
      "Imagine.mp3\n",
      "VIva La Vida.mp3\n",
      "Program running time (in second) 200.9102168083191\n"
     ]
    }
   ],
   "source": [
    "T1 =time.time()\n",
    "make_database()\n",
    "T2 = time.time()\n",
    "print('Program running time (in second)', T2 - T1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Five Hundred Miles.mp3' '6.7903865365e-313' 'Canon.mp3'\n",
      " 'Men Without Hats.mp3' 'Blinding Lights.mp3' 'Imagine.mp3'\n",
      " 'VIva La Vida.mp3' '2.440295160183e-312' '2.31297541238e-312'\n",
      " '1.082217853946e-312']\n"
     ]
    }
   ],
   "source": [
    "print(songid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(hashtable[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1s9p0UqJU9s_"
   },
   "source": [
    "## Part 2\n",
    "\n",
    "Part 2 of the project will be buiding the part of Shazam that identifies the segment of music.\n",
    "The main steps of the algorithm are the following:\n",
    "- Load HASHTABLE and SONGID that were createdin part 1. \n",
    "- Prepare a clip of music for identification.\n",
    "- Extract the list of frequency pairs from the clip.\n",
    "- Look up matches in the hash table, calculate time offsets, and sort them by song. \n",
    "- Identify the song with the most matches for a single consistent timing offset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdPx5NsRU9tC"
   },
   "source": [
    "### 2.1 and 2.2 Extracting Features from the Input Clip and Recovering matches from hash table\n",
    "\n",
    "Use the frequencies and the time difference of the peak pair (f1, f2, t2 − t1) as inputs to the hash function. Then extract the two lists from the hash table saved at the location provided by the hash function. Then, convert the timing list to a list of timing offsets by subtracting the time t1 that the peak pair occurred in the clip. This list of offsets is what we will save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "id": "fiv3wroGU9tC"
   },
   "outputs": [],
   "source": [
    "def match_segment(sr, data):\n",
    "    \"\"\"\n",
    "    Takes in the data and sample rate of an audio file\n",
    "    Creates a fingerprint for the data and attempts to match this against the database\n",
    "    Fingerprint is then checked for collisions against the database hashtable\n",
    "    Determines a confidence level based on the percentage of occurences for the most common timing offset\n",
    "    Returns the songid of the most likely match\n",
    "    Returns the confidence in the match\n",
    "    \"\"\"\n",
    "    global hashtable\n",
    "    global songid\n",
    "    \n",
    "    hashtable = np.load('hashtable.npy', allow_pickle=True)\n",
    "    songid = np.load('songid.npy', allow_pickle=True)\n",
    "    hash_song_dict = hashtable[0]\n",
    "    hash_pair_dict = hashtable[1]\n",
    "    \n",
    "    hashTableSize = len(hashtable[0])\n",
    "    \n",
    "    fp = fingerprint(sr, data)\n",
    "    tup = ctp(fp)\n",
    "    \n",
    "    mat = {}\n",
    "    \n",
    "        \n",
    "    for k in range(len(tup)):\n",
    "        clip_hash = simple_hash(tup[k][2], tup[k][3], tup[k][1]-tup[k][0], 100000)# TODO compute the hash value\n",
    "        if (clip_hash in hash_song_dict.keys()):\n",
    "            matchID = hash_song_dict[clip_hash] # songid, a list\n",
    "            matchTime = hash_pair_dict[clip_hash] # those features, a list\n",
    "            \n",
    "            for j in range(len(matchID)):\n",
    "                song_name = matchID[j]\n",
    "                if song_name in mat:\n",
    "                    mat[song_name] += 1\n",
    "                else:\n",
    "                    mat[song_name] = 1\n",
    "    \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Ht94QzWU9tC"
   },
   "source": [
    "### 2.3 Identifying the song\n",
    "\n",
    "Find the song that has the most occurrences of any single timing offset. This is most easily done by looping through each song and using the mode command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "id": "zOudm2rhU9tD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program run time: 9.155421257019043\n"
     ]
    }
   ],
   "source": [
    "# example usage\n",
    "T3 = time.time()\n",
    "sr1, data1 = wav_load(\"viva.mp3\", trained=False) #Not in database\n",
    "songs = match_segment(sr1, data1)\n",
    "T4 = time.time()\n",
    "print('program run time:', (T4 - T3))\n",
    "# load the files given to you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Match Song in descending order by value :  {'VIva La Vida.mp3': 1642878, 'Blinding Lights.mp3': 1233446, 'Men Without Hats.mp3': 774946, 'Imagine.mp3': 720134, 'Canon.mp3': 382694, 'Five Hundred Miles.mp3': 234464}\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "sorted_d = dict( sorted(songs.items(), key=operator.itemgetter(1),reverse=True))\n",
    "print('Best Match Song in descending order by value : ',sorted_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program run time: 13.609328031539917\n",
      "Best Match Song in descending order by value :  {'Blinding Lights.mp3': 7711840, 'VIva La Vida.mp3': 7215528, 'Imagine.mp3': 5562532, 'Men Without Hats.mp3': 5288820, 'Canon.mp3': 2924328, 'Five Hundred Miles.mp3': 2636995}\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "T3 = time.time()\n",
    "sr1, data1 = wav_load(\"Blinding Lights (sample).mp3\", trained=False) #Not in database\n",
    "songs = match_segment(sr1, data1)\n",
    "T4 = time.time()\n",
    "print('program run time:', (T4 - T3))\n",
    "sorted_d = dict(sorted(songs.items(), key=operator.itemgetter(1),reverse=True))\n",
    "print('Best Match Song in descending order by value : ',sorted_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program run time: 11.605187177658081\n",
      "Best Match Song in descending order by value :  {'Canon.mp3': 4609537, 'Imagine.mp3': 3787366, 'Blinding Lights.mp3': 3745250, 'VIva La Vida.mp3': 3482110, 'Men Without Hats.mp3': 3012780, 'Five Hundred Miles.mp3': 2986689}\n"
     ]
    }
   ],
   "source": [
    "T3 = time.time()\n",
    "sr1, data1 = wav_load(\"Canon (mp3cut.net).mp3\", trained=False) #Not in database\n",
    "songs = match_segment(sr1, data1)\n",
    "T4 = time.time()\n",
    "print('program run time:', (T4 - T3))\n",
    "sorted_d = dict(sorted(songs.items(), key=operator.itemgetter(1),reverse=True))\n",
    "print('Best Match Song in descending order by value : ',sorted_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Final_Project_Shazam.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
